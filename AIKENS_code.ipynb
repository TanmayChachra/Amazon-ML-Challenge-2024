{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905e25f-3b7d-4343-beac-d6dd12e959b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_unit_map = {\n",
    "    'width': [\n",
    "        ['centimetre', 'centimetres', 'cm', 'cms'],\n",
    "        ['foot', 'feet', 'ft'],\n",
    "        ['inch', 'inches', 'in', '\"'],\n",
    "        ['metre', 'meter', 'meters', 'm'],\n",
    "        ['millimetre', 'millimeter', 'millimeters', 'mm'],\n",
    "        ['yard', 'yards', 'yd', 'yds']\n",
    "    ],\n",
    "    'depth': [\n",
    "        ['centimetre', 'centimetres', 'cm', 'cms'],\n",
    "        ['foot', 'feet', 'ft'],\n",
    "        ['inch', 'inches', 'in'],\n",
    "        ['metre', 'meter', 'meters', 'm'],\n",
    "        ['millimetre', 'millimeter', 'millimeters', 'mm'],\n",
    "        ['yard', 'yards', 'yd', 'yds']\n",
    "    ],\n",
    "    'height': [\n",
    "        ['centimetre', 'centimetres', 'cm', 'cms'],\n",
    "        ['foot', 'feet', 'ft'],\n",
    "        ['inch', 'inches', 'in'],\n",
    "        ['metre', 'meter', 'meters', 'm'],\n",
    "        ['millimetre', 'millimeter', 'millimeters', 'mm'],\n",
    "        ['yard', 'yards', 'yd', 'yds']\n",
    "    ],\n",
    "    'item_weight': [\n",
    "        ['gram', 'grams', 'g'],\n",
    "        ['kilogram', 'kilograms', 'kg', 'kgs'],\n",
    "        ['microgram', 'micrograms', 'μg', 'mcg'],\n",
    "        ['milligram', 'milligrams', 'mg'],\n",
    "        ['ounce', 'ounces', 'oz'],\n",
    "        ['pound', 'pounds', 'lb', 'lbs'],\n",
    "        ['ton', 'tons', 't']\n",
    "    ],\n",
    "    'maximum_weight_recommendation': [\n",
    "        ['gram', 'grams', 'g'],\n",
    "        ['kilogram', 'kilograms', 'kg', 'kgs'],\n",
    "        ['microgram', 'micrograms', 'μg', 'mcg'],\n",
    "        ['milligram', 'milligrams', 'mg'],\n",
    "        ['ounce', 'ounces', 'oz'],\n",
    "        ['pound', 'pounds', 'lb', 'lbs'],\n",
    "        ['ton', 'tons', 't']\n",
    "    ],\n",
    "    'voltage': [\n",
    "        ['kilovolt', 'kilovolts', 'kv'],\n",
    "        ['millivolt', 'millivolts', 'mv'],\n",
    "        ['volt', 'volts', 'v']\n",
    "    ],\n",
    "    'wattage': [\n",
    "        ['kilowatt', 'kilowatts', 'kw'],\n",
    "        ['watt', 'watts', 'w']\n",
    "    ],\n",
    "    'item_volume': [\n",
    "        ['centilitre', 'centiliter', 'centiliters', 'cl'],\n",
    "        ['cubic foot', 'cubic feet', 'cu ft', 'ft³'],\n",
    "        ['cubic inch', 'cubic inches', 'cu in', 'in³'],\n",
    "        ['cup', 'cups'],\n",
    "        ['decilitre', 'deciliter', 'deciliters', 'dl'],\n",
    "        ['fluid ounce', 'fluid ounces', 'fl oz'],\n",
    "        ['gallon', 'gallons', 'gal'],\n",
    "        ['imperial gallon', 'imperial gallons', 'imp gal'],\n",
    "        ['litre', 'liter', 'liters', 'litres', 'l'],\n",
    "        ['microlitre', 'microliter', 'microliters', 'microlitres', 'μl', 'mcl'],\n",
    "        ['millilitre', 'milliliter', 'milliliters', 'millilitres', 'ml'],\n",
    "        ['pint', 'pints', 'pt'],\n",
    "        ['quart', 'quarts', 'qt']\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b22afe-60bd-40bc-aff1-89fc6e08cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Initialize the PaddleOCR model with the angle classifier\n",
    "ocr = PaddleOCR(use_angle_cls=True)\n",
    "\n",
    "# Define relative paths\n",
    "BASE_PATH = os.getcwd()\n",
    "IMAGES_FOLDER = os.path.join(BASE_PATH, 'test_images')\n",
    "DATASET_FOLDER = os.path.join(BASE_PATH, 'dataset')\n",
    "\n",
    "def run_OCR(image_name):\n",
    "    \"\"\"\n",
    "    Perform OCR using the pre-trained text detection model.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_name: The name of the image file to be processed.\n",
    "    \n",
    "    Returns:\n",
    "    - result: OCR results for the image.\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(IMAGES_FOLDER, image_name)\n",
    "    result = ocr.ocr(image_path)\n",
    "    return result\n",
    "\n",
    "def name_parser(image_link):\n",
    "    \"\"\"\n",
    "    Parse the URL to get the image name from the path.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_link: The URL of the image.\n",
    "    \n",
    "    Returns:\n",
    "    - image_name: The name of the image extracted from the URL.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(image_link)\n",
    "    path = parsed_url.path\n",
    "    image_name = path.split('/')[-1]\n",
    "    return image_name\n",
    "\n",
    "def split_alphanumeric_with_special_chars(string):\n",
    "    \"\"\"\n",
    "    Split the alphanumeric string into numbers with units and standalone numbers.\n",
    "    \n",
    "    Parameters:\n",
    "    - string: The string containing numbers and units.\n",
    "    \n",
    "    Returns:\n",
    "    - numbers_with_units: List of tuples containing numbers and their units.\n",
    "    - standalone_numbers: List of standalone numbers.\n",
    "    \"\"\"\n",
    "    matches = re.findall(r'(\\d+\\.?\\,?\\d*)([a-zA-Z]+)?', string)\n",
    "    numbers_with_units = []\n",
    "    standalone_numbers = []\n",
    "    \n",
    "    for match in matches:\n",
    "        number, unit = match\n",
    "        number = number.replace(\",\", \".\")\n",
    "        if unit:\n",
    "            numbers_with_units.append((float(number), unit))\n",
    "        else:\n",
    "            standalone_numbers.append(float(number))\n",
    "    \n",
    "    return numbers_with_units, standalone_numbers\n",
    "\n",
    "def map_to_standard_unit(unit, entity_name):\n",
    "    \"\"\"\n",
    "    Map a given unit to the standard (0th index) unit in the entity_unit_map.\n",
    "    \n",
    "    Parameters:\n",
    "    - unit: The unit to be mapped.\n",
    "    - entity_name: The name of the entity for which the unit is being mapped.\n",
    "    \n",
    "    Returns:\n",
    "    - The standard unit if found, otherwise None.\n",
    "    \"\"\"\n",
    "    for unit_list in entity_unit_map[entity_name]:\n",
    "        if unit.lower() in [u.lower() for u in unit_list]:\n",
    "            return unit_list[0]  # Return the first entry as the standard unit\n",
    "    return None\n",
    "\n",
    "count = 1\n",
    "def predictor(image_link, category_id, entity_name):\n",
    "    \"\"\"\n",
    "    Generate predictions for an image by extracting numbers and units using OCR.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_link: The URL of the image to be processed.\n",
    "    - category_id: The category ID of the image (not used in the current implementation).\n",
    "    - entity_name: The name of the entity for unit mapping.\n",
    "    \n",
    "    Returns:\n",
    "    - The predicted value in the format \"{number} {unit}\" or the first standalone number if no unit is found.\n",
    "    \"\"\"\n",
    "    global index, count\n",
    "    print()\n",
    "    print(f\"Count: {count}, Index: {index}\")\n",
    "    print(image_link)\n",
    "    count += 1\n",
    "\n",
    "    OCR_result = run_OCR(name_parser(image_link))        \n",
    "    result_modified = []\n",
    "    contains_number = False\n",
    "    \n",
    "    # Splitting number + entity into two different results\n",
    "    for line in OCR_result:\n",
    "        if not line:\n",
    "            return \"\"\n",
    "        for word_info in line:\n",
    "            numbers_with_units, standalone_numbers = split_alphanumeric_with_special_chars(word_info[1][0])\n",
    "            \n",
    "            # Add the number with unit to the result_modified\n",
    "            for number, unit in numbers_with_units:\n",
    "                standard_unit = map_to_standard_unit(unit, entity_name)\n",
    "                if standard_unit:  # Only add if unit is found in entity_unit_map\n",
    "                    result_modified.append([number, standard_unit, word_info[0]])\n",
    "                    contains_number = True\n",
    "            \n",
    "            # Add standalone numbers (without a unit)\n",
    "            for number in standalone_numbers:\n",
    "                result_modified.append([number, None, word_info[0]])\n",
    "                contains_number = True\n",
    "            \n",
    "            # Check for standalone units and map them to standard units\n",
    "            alphabets = re.findall(r'[a-zA-Z]+', word_info[1][0])\n",
    "            for word in alphabets:\n",
    "                for unit_list in entity_unit_map[entity_name]:\n",
    "                    if word.lower() in unit_list:\n",
    "                        result_modified.append([unit_list[0], word_info[0]])  # Use the first entry in the unit list\n",
    "                        break\n",
    "    \n",
    "    # If there are no numbers or units, return an empty string\n",
    "    if result_modified == [] or not contains_number:\n",
    "        return \"\"\n",
    "    \n",
    "    # Filter results based on the entity type\n",
    "    filtered_results = []\n",
    "    for item in result_modified:\n",
    "        if len(item) == 3:  # number with unit\n",
    "            number, unit, coordinates = item\n",
    "            if unit:\n",
    "                filtered_results.append((number, unit, coordinates))\n",
    "        elif len(item) == 2 and isinstance(item[0], str):  # standalone unit\n",
    "            filtered_results.append(item)\n",
    "    \n",
    "    if not filtered_results:\n",
    "        return \"\"\n",
    "    \n",
    "    # If we have a number with the correct unit, return it in the format \"{number} {unit}\"\n",
    "    for item in filtered_results:\n",
    "        if len(item) == 3:\n",
    "            number, unit, _ = item\n",
    "            return f\"{number} {unit}\"\n",
    "    \n",
    "    # If no number with unit, check the closest number to a standalone unit\n",
    "    min_distance = float('inf')\n",
    "    closest_number = None\n",
    "    closest_unit = None\n",
    "    \n",
    "    for i in range(len(filtered_results)):\n",
    "        if len(filtered_results[i]) == 3:  # number with coordinates\n",
    "            number, _, coordinates = filtered_results[i]\n",
    "            xi_center = sum(coord[0] for coord in coordinates) / 4\n",
    "            yi_center = sum(coord[1] for coord in coordinates) / 4\n",
    "            \n",
    "            for j in range(len(filtered_results)):\n",
    "                if len(filtered_results[j]) == 2 and isinstance(filtered_results[j][0], str):  # standalone unit\n",
    "                    unit, unit_coordinates = filtered_results[j]\n",
    "                    xj_center = sum(coord[0] for coord in unit_coordinates) / 4\n",
    "                    yj_center = sum(coord[1] for coord in unit_coordinates) / 4\n",
    "                    \n",
    "                    distance = ((xi_center - xj_center) * 2 + (yi_center - yj_center) * 2) ** 0.5\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        closest_number = number\n",
    "                        closest_unit = unit\n",
    "    \n",
    "    if closest_number is not None and closest_unit is not None:\n",
    "        return f\"{closest_number} {closest_unit}\"\n",
    "    \n",
    "    # If we still haven't found a match, return the first number with space\n",
    "    return f\"{filtered_results[0][0]}\" if len(filtered_results[0]) == 3 else \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to input and output files\n",
    "    input_file = os.path.join(DATASET_FOLDER, 'test.csv')  # Change to the full CSV file\n",
    "    output_file = os.path.join(DATASET_FOLDER, 'test_out.csv')  # Output file\n",
    "    \n",
    "    # Read the test data\n",
    "    test = pd.read_csv(input_file)\n",
    "    \n",
    "    # Initialize the starting index from the \"index\" column\n",
    "    start_index = 0\n",
    "    \n",
    "    # If the output file exists, get the last processed index from the \"index\" column\n",
    "    if os.path.exists(output_file):\n",
    "        try:\n",
    "            last_line = pd.read_csv(output_file).tail(1)\n",
    "            start_index = last_line['index'].values[0] + 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading the output file: {e}\")\n",
    "            start_index = 0\n",
    "    \n",
    "    # Allow custom starting points, overriding the automatic start index if needed\n",
    "    custom_start_index = 0  # Process from the beginning\n",
    "    start_index = max(start_index, custom_start_index)\n",
    "    \n",
    "    # Empty list to store temporary results\n",
    "    results_list = []\n",
    "    \n",
    "    # Iterate through the rows of the test data starting from start_index in the \"index\" column\n",
    "    for _, row in test[test['index'] >= start_index].iterrows():\n",
    "        index = row['index']\n",
    "        \n",
    "        # Check if we need to stop after processing 200 rows\n",
    "        # Comment out this condition to process all rows\n",
    "        # if (index - start_index) % 500 == 0 and index > start_index:\n",
    "        #     print(f\"Stopping at index {index}.\")\n",
    "        #     break\n",
    "        \n",
    "        prediction = predictor(row['image_link'], row['group_id'], row['entity_name'])\n",
    "        \n",
    "        # Append the result to the list\n",
    "        results_list.append({'index': index, 'prediction': prediction})\n",
    "        \n",
    "        # Every 500 iterations, append to CSV and clear list\n",
    "        if (index + 1) % 500 == 0:\n",
    "            results_df = pd.DataFrame(results_list)\n",
    "            results_df.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n",
    "            results_list.clear()\n",
    "    \n",
    "    # After the loop, write any remaining rows in the list\n",
    "    if results_list:\n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        results_df.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1fb800-e887-4773-a143-c01daf4cbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print done when code completes\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
